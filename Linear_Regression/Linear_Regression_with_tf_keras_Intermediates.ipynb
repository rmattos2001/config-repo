{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Day4: Linear_Regression with tf.keras - Intermediates.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmattos2001/config-repo/blob/master/Linear_Regression/Linear_Regression_with_tf_keras_Intermediates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmHsf5DWsxr6"
      },
      "source": [
        "# Agenda\n",
        "1. Acerca del conjunto de datos\n",
        "2. Objetivo\n",
        "3. Cargando Bibliotecas\n",
        "4. Carga de datos\n",
        "5. Ver datos\n",
        "6. Funciones de entrada y funciones de salida separadas\n",
        "7. Dividir(***Split***) los datos en tren y conjunto de prueba\n",
        "8. Entrenar(***Train***) el modelo (El ciclo de vida del modelo de cinco pasos)\n",
        "   1. Defina el modelo.\n",
        "   2. Compile el modelo.\n",
        "   3. Ajuste el modelo.\n",
        "   4. Evaluar el modelo\n",
        "     * Ajuste de hiperparámetros\n",
        "   5. Predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmP7x85xcxkS"
      },
      "source": [
        "## About the Dataset - Acerca del conjunto de datos\n",
        "Estaremos trabajando en un conjunto de datos que proviene de la industria de bienes raíces en Boston (EE. UU.). Esta base de datos contiene 14 atributos. La variable objetivo se refiere al valor medio de las viviendas ocupadas por sus propietarios en 1000 USD.\n",
        "\n",
        "* CRIM: tasa de criminalidad per cápita por ciudad\n",
        "* ZN: proporción de suelo residencial zonificado para lotes de más de 25,000 pies cuadrados.\n",
        "* INDUS: proporción de acres comerciales no minoristas por ciudad\n",
        "* CHAS: variable ficticia del río Charles (= 1 si el tramo limita con el río; 0 en caso contrario)\n",
        "* NOX: concentración de óxidos nítricos (partes por 10 millones)\n",
        "* RM: promedio de cuartos por vivienda\n",
        "* AGE: proporción de unidades ocupadas por sus propietarios construidas antes de 1940\n",
        "* DIS: distancias ponderadas a cinco centros de empleo de Boston\n",
        "* RAD: índice de accesibilidad a las carreteras radiales\n",
        "* TAX: tasa de impuesto a la propiedad de valor total por cada 10,000 USD\n",
        "* PTRATIO: ratio alumno-profesor por municipio\n",
        "* B: 1000(Bk - 0.63)^2 donde Bk es la proporción de negros por ciudad\n",
        "* LSTAT: estado inferior de la población (%)\n",
        "* MEDV: valor medio de las viviendas ocupadas por sus propietarios en 1000 USD (Objetivo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rzbajG5Apht7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_c7y3fqWuDX"
      },
      "source": [
        "## Objective\n",
        "The objective is to use linear regression to find the median value of owner-occupied homes in 1000 USD's.\n",
        "\n",
        "We will build a Machine learning model (i.e. Linear Regression) using `tensorflow.keras` (in short `tf.keras`) API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvnf8jDeTTvw"
      },
      "source": [
        "You already have all the information about Tensorflow and Keras from earlier modules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQeegjzCbXdf"
      },
      "source": [
        "## Loading Libraries\n",
        "All Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n",
        "\n",
        "In data science, numpy and pandas are most commonly used libraries. Numpy is required for calculations like means, medians, square roots, etc. Pandas is used for data processing and data frames. Matplotlib is used for data visualization. We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, matplotlib.pyplot as plt).\n",
        "\n",
        "**pyplot:** pyplot is matplotlib's plotting framework. It is the most used module of matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEWLuXd7BMrU"
      },
      "source": [
        "# importing packages\n",
        "import numpy as np # to perform calculations \n",
        "import pandas as pd # to read data\n",
        "import matplotlib.pyplot as plt # to visualise"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY_eewx0dhHt"
      },
      "source": [
        "## Loading Data\n",
        "Pandas module is used for reading files. We have our data in '.csv' format. We will use 'read_csv()' function for loading the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zlSaTd2W9rt"
      },
      "source": [
        "# In read_csv() function, we have passed the location to where the file is located at dphi official github page\n",
        "boston_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv\" )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wze8jmpKtBG4"
      },
      "source": [
        "## View Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwj5kkDjjQkx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "94f14555-851c-45f9-858c-914767111df1"
      },
      "source": [
        "boston_data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
              "0  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
              "1   0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
              "2   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
              "3   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
              "4   0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  MEDV  \n",
              "0     20.2  349.48  24.91  12.0  \n",
              "1     21.0  395.62   8.47  19.9  \n",
              "2     16.9  362.25   7.83  19.4  \n",
              "3     20.2    2.52  23.29  13.4  \n",
              "4     21.0  390.95  11.28  18.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1324b4c9-9f70-4185-b1ff-39530c756c01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.02340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>5.304</td>\n",
              "      <td>97.3</td>\n",
              "      <td>2.1007</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>349.48</td>\n",
              "      <td>24.91</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.62739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>5.834</td>\n",
              "      <td>56.5</td>\n",
              "      <td>4.4986</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>395.62</td>\n",
              "      <td>8.47</td>\n",
              "      <td>19.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.03466</td>\n",
              "      <td>35.0</td>\n",
              "      <td>6.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4379</td>\n",
              "      <td>6.031</td>\n",
              "      <td>23.3</td>\n",
              "      <td>6.6407</td>\n",
              "      <td>1.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>362.25</td>\n",
              "      <td>7.83</td>\n",
              "      <td>19.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.05042</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>6.103</td>\n",
              "      <td>85.1</td>\n",
              "      <td>2.0218</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>2.52</td>\n",
              "      <td>23.29</td>\n",
              "      <td>13.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.72580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>5.727</td>\n",
              "      <td>69.5</td>\n",
              "      <td>3.7965</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>390.95</td>\n",
              "      <td>11.28</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1324b4c9-9f70-4185-b1ff-39530c756c01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1324b4c9-9f70-4185-b1ff-39530c756c01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1324b4c9-9f70-4185-b1ff-39530c756c01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBv1fy29jAzm"
      },
      "source": [
        "# Separating Input Features and Output Features - Separación de entidades de entrada y entidades de salida\n",
        "Antes de construir cualquier modelo de aprendizaje automático, siempre separamos las variables de entrada y las variables de salida. Las variables de entrada son aquellas cantidades cuyos valores cambian naturalmente en un experimento, mientras que la variable de salida es aquella cuyos valores dependen de las variables de entrada. Por lo tanto, las variables de entrada también se conocen como variables independientes, ya que sus valores no dependen de ninguna otra cantidad, y las variables de salida también se conocen como variables dependientes, ya que sus valores dependen de otra variable, es decir, variables de entrada. Como aquí en estos datos, estamos tratando de predecir el precio de un house, por lo que esta es nuestra columna de destino, es decir, 'MEDV'\n",
        "\n",
        "Por convención, las variables de entrada se representan con ***'X'*** y las variables de salida se representan con ***'y'***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErMptop0jyng"
      },
      "source": [
        "X = boston_data.drop('MEDV', axis = 1)    # Input Variables/features\n",
        "y = boston_data.MEDV      # output variables/features"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6mqY54VExSs",
        "outputId": "0f590de9-7dc5-4310-a145-b592fa26998e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      12.0\n",
              "1      19.9\n",
              "2      19.4\n",
              "3      13.4\n",
              "4      18.2\n",
              "       ... \n",
              "399    19.5\n",
              "400    21.1\n",
              "401    24.5\n",
              "402    13.4\n",
              "403    18.6\n",
              "Name: MEDV, Length: 404, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgXPagiS3YKz"
      },
      "source": [
        "# Splitting the data - Dividir los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vOkLlB-Ukjn"
      },
      "source": [
        "Queremos comprobar el rendimiento del modelo que construimos. Para este propósito, siempre dividimos(***split***) (tanto los datos de entrada como los de salida) los datos proporcionados en un conjunto de entrenamiento que se usará para entrenar el modelo y un conjunto de prueba que se usará para verificar la precisión con la que el modelo predice los resultados.\n",
        "\n",
        "Para ello tenemos una clase llamada ***'train_test_split'*** en el módulo ***'sklearn.model_selection'***.\n",
        "\n",
        "Dividimos(***split***) el 80% de los datos en el conjunto de entrenamiento, mientras que el 20% de los datos en el conjunto de prueba usando el código siguiente.\n",
        "La variable ***test_size*** es donde realmente especificamos la proporción del conjunto de prueba.\n",
        "\n",
        "Al pasar nuestras variables X e Y al método ***train_test_split***, podemos capturar las divisiones en los datos asignando 4 variables al resultado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a1OFJmpUl2u"
      },
      "source": [
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Assign variables to capture train test split output\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train: independent/input datos característicos para entrenar el modelo\n",
        "# y_train: dependent/output datos característicos para entrenar el modelo\n",
        "# X_test: independent/input datos de características para probar el modelo; se utilizará para predecir los valores de salida\n",
        "# y_test: original dependent/output values of X_test; Compararemos estos valores con nuestros valores predichos para verificar el rendimiento de nuestro modelo construido.\n",
        " \n",
        "# test_size = 0,20: el 20 % de los datos se destinará al conjunto de prueba y el 80 % de los datos se destinará al conjunto de entrenamiento\n",
        "# random_state = 42: esto solucionará la división, es decir, habrá la misma división cada vez que ejecute el código"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfKNjpJqkPUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8462733f-6c41-46bb-efed-e2276c00cfb7"
      },
      "source": [
        "# find the number of input features\n",
        "n_features = X.shape[1]\n",
        "print(n_features)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwotIN0AU3Ci"
      },
      "source": [
        "# Training our model - entrenando a nuestro modelo\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EV_0iiBMBz6"
      },
      "source": [
        "Después de dividir los datos en conjuntos de prueba y entrenamiento, es hora de entrenar nuestro primer modelo de aprendizaje profundo. ¡Esperar! Antes de entrenar el modelo de aprendizaje profundo, comprendamos el **Deep Learning Model Life-Cycle**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3XXW9NL6H4s"
      },
      "source": [
        "## Neural Network: Architecture\n",
        "Aquí le ofrecemos solo una descripción general de la arquitectura de Neural Network. Sabrá más sobre esto en el próximo módulo.\n",
        "\n",
        "Las redes neuronales consisten en una capa de entrada y salida con una o más capas ocultas.\n",
        "\n",
        "![neural network architecture](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/nn+arch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymbh14OgMu2Z"
      },
      "source": [
        "## The 5 Step Model Life-Cycle - El ciclo de vida del modelo de 5 pasos\n",
        "\n",
        "Un modelo tiene un ciclo de vida, y este conocimiento muy simple proporciona la columna vertebral tanto para modelar un conjunto de datos como para comprender la API tf.keras.\n",
        "\n",
        "Los cinco pasos en el ciclo de vida son los siguientes:\n",
        "\n",
        "1. Defina el modelo.\n",
        "2. Compile el modelo.\n",
        "3. Ajuste el modelo.\n",
        "4. Hacer predicciones sobre los datos de prueba.\n",
        "5. Evaluar el modelo.\n",
        "\n",
        "Examinaremos más de cerca cada uno de los pasos y, en paralelo, construiremos el modelo de aprendizaje profundo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auQ5lPFrN7GN"
      },
      "source": [
        "### 1. Definir el modelo\n",
        "Definir el modelo requiere que primero seleccione el tipo de modelo que necesita y luego elija la arquitectura o topología de red.\n",
        "\n",
        "Desde la perspectiva de la API, esto implica definir las capas del modelo, configurar cada capa con una cantidad de nodos y una función de activación, y conectar las capas en un modelo cohesivo.\n",
        "\n",
        "Los modelos se pueden definir con la API secuencial o la API funcional (lo sabrá en módulos posteriores). Aquí definiremos el modelo con Sequential API. Ahora **¿qué es la API secuencial?**\n",
        "\n",
        "**API secuencial**\n",
        "La API secuencial es la API más simple para comenzar con Deep Learning.\n",
        "\n",
        "Se denomina \"secuencial\" porque implica definir una clase secuencial y agregar capas al modelo una por una de manera lineal, desde la entrada hasta la salida.\n",
        "\n",
        "El siguiente ejemplo define un modelo de MLP secuencial que acepta una entrada (es decir, 'YearsExperience'), tiene una capa oculta con 1 nodo y luego una capa de salida con un nodo para predecir un valor numérico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY303RWVPzkD"
      },
      "source": [
        "from tensorflow.keras import Sequential    # import Sequential from tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense  # import Dense from tensorflow.keras.layers\n",
        "from numpy.random import seed     # seed helps you to fix the randomness in the neural network.  \n",
        "import tensorflow"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMDrQE9gQP6U"
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "#Funcion de activacion ReLU\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,))) #Capa visible\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ntHsm1QnLP"
      },
      "source": [
        "Tenga en cuenta que la capa visible de la red está definida por el argumento \"input_shape\" en la primera capa oculta. Eso significa que en el ejemplo anterior, el modelo espera que la entrada para una muestra sea un vector de n_features (es decir, 13) number .\n",
        "\n",
        "La API secuencial es fácil de usar porque sigues llamando a model.add() hasta que hayas agregado todas tus capas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABBhVYtXRlJq"
      },
      "source": [
        "La función de activación que hemos elegido es **ReLU**, que significa **rectified linear unit**. La función de activación decide si una neurona debe activarse o no.\n",
        "\n",
        "ReLU se define matemáticamente como **F(x) = max(0,x)**. En otras palabras, la salida es x, si x es mayor que 0, y la salida es 0 si x es 0 o negativo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D100gBMQSTn8"
      },
      "source": [
        "### 2. Compile the model - Compilar el modelo\n",
        "\n",
        "La compilación del modelo requiere que primero seleccione una función de pérdida que desee optimizar, como el error cuadrático medio o la entropía cruzada.\n",
        "\n",
        "También requiere que seleccione un algoritmo para realizar el procedimiento de optimización. Estamos usando **RMSprop** como nuestro optimizador aquí. RMSprop significa **Propagación cuadrática media de la raíz**(**Root Mean Square Propagation**). Es uno de los algoritmos de optimización de gradiente descendente más populares para redes de aprendizaje profundo. RMSprop es un optimizador fiable y rápido.\n",
        "\n",
        "**Nota:** Por el momento, entienda el descenso de gradiente solo como un algoritmo de optimización. Sabrá más sobre esto en el próximo módulo.\n",
        "\n",
        "También puede requerir que seleccione cualquier métrica de rendimiento para realizar un seguimiento durante el proceso de capacitación del modelo. La función de pérdida que se usa aquí es **error cuadrático medio.**(**mean squared error.**) (no se preocupe si no conoce el error cuadrático medio de la función de pérdida, por el momento sepa que es una función que le ayuda a conocer el error o la pérdida su modelo está dando. Aprenderá más sobre las funciones de pérdida en los próximos módulos)\n",
        "\n",
        "Desde la perspectiva de una API, esto implica llamar a una función para compilar el modelo con la configuración elegida, que preparará las estructuras de datos adecuadas necesarias para el uso eficiente del modelo que ha definido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doYNy1jJQa7J"
      },
      "source": [
        "# import RMSprop optimizer\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "optimizer = RMSprop(0.01)    # 0.01 is the tasa de aprendizaje"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiOzHe6K8iaM"
      },
      "source": [
        "**Why learning rate = 0.01?** (**¿Por qué tasa de aprendizaje = 0.01?**)\n",
        "\n",
        "Es importante encontrar un buen valor para la tasa de aprendizaje de su modelo en su conjunto de datos de entrenamiento. no podemos calcular analíticamente la tasa de aprendizaje óptima para un modelo dado en un conjunto de datos dado. En cambio, se debe descubrir una tasa de aprendizaje buena (o suficientemente buena) a través de prueba y error.\n",
        "\n",
        "El rango de valores a considerar para la tasa de aprendizaje es inferior a 1,0 y superior a $10^{-6}$.\n",
        "\n",
        "Un valor predeterminado tradicional para la tasa de aprendizaje es 0,1 o 0,01, y esto puede representar un buen punto de partida para su problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxnRf2uUqev"
      },
      "source": [
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQPPF22pVHMU"
      },
      "source": [
        "### 3. Fitting the model - Ajuste del modelo\n",
        "\n",
        "Ajustar el modelo requiere que primero seleccione la configuración de entrenamiento, como el número de épocas (bucles a través del conjunto de datos de entrenamiento) y el tamaño del lote (número de muestras en una época usada para estimar el error del modelo).\n",
        "\n",
        "El entrenamiento aplica el algoritmo de optimización elegido para minimizar la función de pérdida elegida y actualiza el modelo utilizando la propagación hacia atrás (no se preocupe si no conoce este término, lo sabrá en el siguiente módulo) del algoritmo de error.\n",
        "\n",
        "Ajustar el modelo es la parte lenta de todo el proceso y puede llevar de segundos a horas o días, según la complejidad del modelo, el hardware que esté usando y el tamaño del conjunto de datos de entrenamiento.\n",
        "\n",
        "Desde la perspectiva de la API, esto implica llamar a una función para realizar el proceso de entrenamiento. Esta función bloqueará (no regresará) hasta que finalice el proceso de entrenamiento.\n",
        "\n",
        "Mientras ajusta el modelo, una barra de progreso resumirá el estado de cada época y el proceso de entrenamiento general."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnG7pev1UxNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a356a08-2bb7-4af9-fb6c-f4d3c1c048dc"
      },
      "source": [
        "seed_value = 42\n",
        "seed(seed_value)        # If you build the model with given parameters, set_random_seed will help you produce the same result on multiple execution\n",
        "\n",
        "\n",
        "# Recommended by Keras -------------------------------------------------------------------------------------\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "# Recommended by Keras -------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "tensorflow.random.set_seed(seed_value) \n",
        "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose = 1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 2221.3962\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 486.7673\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 825.4186\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 612.8762\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 239.1761\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 578.5360\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 399.5109\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 335.9424\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 381.7988\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 277.8728\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f56ae8ead50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZzI8-Kl_Rdg"
      },
      "source": [
        "What is **verbose**?\n",
        "\n",
        "Al configurar detallado 0, 1 o 2, solo dice cómo desea 'ver' el progreso del entrenamiento para cada época.\n",
        "\n",
        "`verbose=0` no te mostrará nada (silencio)\n",
        "\n",
        "`verbose=1` le mostrará una barra de progreso animada como esta:\n",
        "\n",
        "![progres_bar](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/progress+bar.png)\n",
        "\n",
        "`verbose=2` solo mencionará el número de época como esta:\n",
        "\n",
        "![verbose = 2](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/epoch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_tKcVVzhJf8"
      },
      "source": [
        "### 4. Evaluate the model - Evaluar el modelo\n",
        "La evaluación del modelo requiere que primero elija un conjunto de datos de exclusión utilizado para evaluar el modelo. Estos deben ser datos que no se utilicen en el proceso de entrenamiento, es decir, el X_test.\n",
        "\n",
        "La velocidad de evaluación del modelo es proporcional a la cantidad de datos que desea utilizar para la evaluación, aunque es mucho más rápido que el entrenamiento ya que el modelo no cambia.\n",
        "\n",
        "Desde la perspectiva de la API, esto implica llamar a una función con el conjunto de datos reservado y obtener una pérdida y quizás otras métricas que se puedan informar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC63QoqchIa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78ce6d8-0687-4615-9e31-ea82fd74ab94"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 599.1170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "599.1170043945312"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHM4sYEOnD7j"
      },
      "source": [
        "El error cuadrático medio que obtuvimos aquí es 64,8. Ahora, **¿qué significa?** (**what does it mean?**)\n",
        "\n",
        "Cuando resta los valores pronosticados (de los datos de X_test) del valor actual (de los datos de X_test), luego eleva al cuadrado y suma todos los cuadrados, y finalmente toma una media (es decir, un promedio), el resultado que obtendrá es 64,8 pulgadas. este caso.\n",
        "\n",
        "evaluar() hace esta tarea automáticamente. Si desea obtener la predicción para X_test, puede hacer **`model.predict(X_test)`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li94FIlfnMBB"
      },
      "source": [
        "#### Hyperparameter Tunning - Ajuste de hiperparámetros\n",
        "\n",
        "Los hiperparámetros aquí en este cuaderno son:\n",
        "1. Learning Rate - Tasa de aprendizaje\n",
        "2. Epochs - Épocas\n",
        "3. Batch Size - Tamaño del lote\n",
        "\n",
        "Podemos probar y cambiar los valores de estos parámetros y ver el rendimiento del modelo (evaluar el modelo) en los datos de X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XljOzViRoRbp"
      },
      "source": [
        "**Learning Rate** -**Tasa de aprendizaje**\n",
        "\n",
        "Un escalar utilizado para entrenar un modelo a través del descenso de gradiente. Durante cada iteración, el algoritmo de **descenso de gradiente** (**gradient descent**) multiplica la tasa de aprendizaje por el gradiente. El producto resultante se llama **paso de gradiente**(**gradient step**).\n",
        "\n",
        "La tasa de aprendizaje es un **hyperparameter** clave."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puhKnL9KKuZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62906188-d166-4fb8-ed70-cf7fcd4baee8"
      },
      "source": [
        "####################### Complete example to check the performance of the model with different learning rates #######################################\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "\n",
        "# fit the model \n",
        "model.fit(X_train, y_train, epochs=10, batch_size=30, verbose = 1)\n",
        "\n",
        "# evaluate the model\n",
        "print('The MSE value is: ', model.evaluate(X_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 1s 3ms/step - loss: 35268.1836\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 559.4072\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 212.1512\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 139.3775\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 129.5609\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 122.8495\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 174.4109\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 142.8208\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 201.2052\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 223.9953\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 122.8359\n",
            "The MSE value is:  122.8359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPneBHxHYxfC"
      },
      "source": [
        "Como puede ver arriba, cómo ha cambiado la pérdida (costo), es decir, MSE, simplemente cambiando la tasa de aprendizaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhi50q4rhUiF"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Test several learning rate values to see the impact of varying this value when defining your model.\n",
        "\n",
        "Pruebe varios valores de tasa de aprendizaje para ver el impacto de variar este valor al definir su modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4BqC2Cfo159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b981115d-31b7-4cff-e6ac-aac59ae86ce9"
      },
      "source": [
        "# Play with learning rate\n",
        "learning_rate = 5.2          # Replace ? with a floating-point number\n",
        "epochs = 10\n",
        "optimizer = RMSprop(learning_rate)\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=30)     # fit the model\n",
        "model.evaluate(X_test, y_test)       # Evaluate the model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 23545565184.0000\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 55675.3672\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 26444.9062\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 7212.5439\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1347.0896\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1213.8527\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1191.9918\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1154.1119\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1089.7484\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 984.5944\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3345.8279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3345.827880859375"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mov9-uVwpmkd"
      },
      "source": [
        "**Epochs** - (**Épocas**)\n",
        "\n",
        "Un pase de entrenamiento completo sobre todo el conjunto de datos de modo que cada ejemplo se haya visto una vez. Por lo tanto, una época representa N/iteraciones de entrenamiento de tamaño de lote, donde N es el número total de ejemplos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlZv50iKZPqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9957544b-7d5f-4d6b-d98f-b2ba9f64ebb0"
      },
      "source": [
        "####################### Ejemplo completo para comprobar el rendimiento del modelo con diferentes épocas y tasa de aprendizaje = 0,01 #######################################\n",
        "# define the model - Definir Modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        " \n",
        "# fit the model  - Ajustar Modelo\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=30, verbose = 1)\n",
        "\n",
        "# evaluate the model - Evaluar Modelo\n",
        "print('The MSE value is: ', model.evaluate(X_test, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 3ms/step - loss: 9724.5742\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 582.0069\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 555.8216\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 521.9397\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 483.8689\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 444.7491\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 406.9054\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 371.2612\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 337.6587\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 306.2268\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 277.0800\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 250.4167\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 225.5309\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 202.9859\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 182.7787\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 164.8227\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 148.9729\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 135.4988\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 123.8988\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 114.1056\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 106.0993\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 100.3444\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 96.4450\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.5845\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.0008\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.3616\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0118\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.1522\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0371\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0573\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9193\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0018\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9787\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9684\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0983\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9732\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9472\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9128\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0360\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9132\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9193\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9364\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8977\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9577\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9994\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0100\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0025\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0074\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9457\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0306\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.1645\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9211\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9330\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8901\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0190\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0044\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0272\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0088\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0335\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8989\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0687\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9590\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9457\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9054\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0399\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9739\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9935\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9428\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9365\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9752\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9980\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0044\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0282\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 91.0151\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9688\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9369\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0542\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9409\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.1157\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9322\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0418\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9078\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.9901\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0322\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0187\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9214\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0568\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8874\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9281\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0325\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9906\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0670\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8633\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9740\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 91.0710\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9303\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9599\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9305\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 91.0165\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.9525\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 71.1146\n",
            "The MSE value is:  71.11458587646484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPakaxBaZZNA"
      },
      "source": [
        "Puede ver arriba cómo la pérdida (cost), es decir, MSE, ha cambiado simplemente cambiando las épocas y manteniendo la tasa de aprendizaje igual a 0.01 (es decir, el primer modelo que construimos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WoG362ohrQF"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Pruebe varios valores de época para ver el impacto de variar este valor al definir su modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUmO4ehKqC2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c0064b-2c8c-4b5e-d500-5553765df4c0"
      },
      "source": [
        "# Play with epochs\n",
        "learning_rate = 0.01         \n",
        "epochs = 10            # Replace ? with an integer\n",
        "optimizer = RMSprop(learning_rate)\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=30)     # fit the model\n",
        "model.evaluate(X_test, y_test)       # Evaluate the model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 90.9072\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8703\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8629\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8708\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8538\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.8574\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8617\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 90.8574\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8547\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.8497\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 71.1205\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.12053680419922"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6cx5vbtqdeD"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Encuentre la mejor combinación posible de ***learning rate - tasa de aprendizaje*** y ***epochs - épocas*** mientras prueba algunas combinaciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8RUGIklqxKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98145ba0-33b3-423c-83cd-bafa176e4294"
      },
      "source": [
        "# play with learning rate and epochs\n",
        "learning_rate = 1.5        # Replace ? with a floating-point number\n",
        "epochs = 10             # Replace ? with an integer\n",
        "optimizer = RMSprop(learning_rate)\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=30)     # fit the model\n",
        "model.evaluate(X_test, y_test)       # Evaluate the model"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 94.3054\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 92.7609\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 92.9094\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 94.2973\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 90.7745\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.6417\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 92.1282\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 92.3171\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 93.0398\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 92.3192\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 71.4844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.48442077636719"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcn3gB3Uq7u6"
      },
      "source": [
        "**Batch Size**\n",
        "\n",
        "The number of examples in a batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTSP63PTZ8hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "d0a90bd0-9e34-49e4-b351-fa035ae6df22"
      },
      "source": [
        "####################### Ejemplo completo para comprobar el rendimiento del modelo con diferentes tamaños de lote manteniendo las épocas en 30 y la tasa de aprendizaje en 0,01 #######################################\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "optimizer = RMSprop(0.1)    # 0.1 es la tasa de aprendizaje\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "\n",
        "# fit the model \n",
        "model.fit(X_train, y_train, epochs=10, batch_size=40, verbose = 1)\n",
        "\n",
        "# evaluate the model\n",
        "print('The MSE value is: ', model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 27410.0840\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 211.4277\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 187.7308\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 157.6277\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 133.5317\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 206.0187\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 335.1154\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 166.5187\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 194.7234\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 181.1730\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833ec5cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 441.9634\n",
            "The MSE value is:  441.9634094238281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7xoMXoVaJy5"
      },
      "source": [
        "Puede ver arriba el valor de costo (pérdida), es decir, MSE para el tamaño de lote 40 mientras mantiene las épocas en 10 y la tasa de aprendizaje en 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9VcjhruiIxd"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "Pruebe varios valores de tamaño de lote para ver el impacto de variar este valor al definir su modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKik9O5grNa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9966d371-01e5-4a1a-b48c-9f83075106ff"
      },
      "source": [
        "# play with batch size\n",
        "learning_rate = 0.01        \n",
        "epochs = 150         \n",
        "batch = 25      # Replace ? with an integer    \n",
        "optimizer = RMSprop(learning_rate)\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch)     # fit the model\n",
        "model.evaluate(X_test, y_test)       # Evaluate the model"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 2ms/step - loss: 91.1562\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 91.0970\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 91.0586\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 91.0386\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 91.0110\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9833\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9740\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9542\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9396\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9353\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.9190\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9106\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9119\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.9089\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8911\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8808\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8770\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8735\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8641\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8632\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8685\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8689\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8565\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8682\n",
            "Epoch 25/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8602\n",
            "Epoch 26/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8514\n",
            "Epoch 27/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8445\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8683\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8577\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8478\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8525\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8582\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8460\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8446\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8596\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8500\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8425\n",
            "Epoch 38/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8419\n",
            "Epoch 39/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8533\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8423\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8481\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8467\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8429\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8453\n",
            "Epoch 45/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8503\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8519\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8487\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8483\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8401\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8563\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8499\n",
            "Epoch 52/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8428\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8429\n",
            "Epoch 54/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8450\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8523\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8499\n",
            "Epoch 57/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8402\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8495\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8481\n",
            "Epoch 60/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8442\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8520\n",
            "Epoch 62/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8487\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8438\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8407\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8518\n",
            "Epoch 66/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8500\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8553\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8482\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8410\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8549\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8393\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8436\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8528\n",
            "Epoch 74/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8500\n",
            "Epoch 75/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8528\n",
            "Epoch 76/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8353\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8536\n",
            "Epoch 78/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8474\n",
            "Epoch 79/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8508\n",
            "Epoch 80/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8435\n",
            "Epoch 81/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8563\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8357\n",
            "Epoch 83/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8456\n",
            "Epoch 84/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8460\n",
            "Epoch 85/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8480\n",
            "Epoch 86/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8427\n",
            "Epoch 87/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8472\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8489\n",
            "Epoch 89/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8453\n",
            "Epoch 90/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8469\n",
            "Epoch 91/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8452\n",
            "Epoch 92/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8516\n",
            "Epoch 93/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8415\n",
            "Epoch 94/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8390\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8539\n",
            "Epoch 96/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8439\n",
            "Epoch 97/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8518\n",
            "Epoch 98/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8437\n",
            "Epoch 99/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8436\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8404\n",
            "Epoch 101/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8537\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8379\n",
            "Epoch 103/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8466\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8401\n",
            "Epoch 105/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8539\n",
            "Epoch 106/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8535\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8407\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8404\n",
            "Epoch 109/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8587\n",
            "Epoch 110/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8510\n",
            "Epoch 111/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8509\n",
            "Epoch 112/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8494\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8416\n",
            "Epoch 114/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8514\n",
            "Epoch 115/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8409\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8432\n",
            "Epoch 117/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8483\n",
            "Epoch 118/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8428\n",
            "Epoch 119/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8463\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8478\n",
            "Epoch 121/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8380\n",
            "Epoch 122/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8407\n",
            "Epoch 123/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8440\n",
            "Epoch 124/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8447\n",
            "Epoch 125/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8415\n",
            "Epoch 126/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8429\n",
            "Epoch 127/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8596\n",
            "Epoch 128/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8514\n",
            "Epoch 129/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8527\n",
            "Epoch 130/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8371\n",
            "Epoch 131/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8522\n",
            "Epoch 132/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8474\n",
            "Epoch 133/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8422\n",
            "Epoch 134/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8486\n",
            "Epoch 135/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8482\n",
            "Epoch 136/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8430\n",
            "Epoch 137/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8428\n",
            "Epoch 138/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8508\n",
            "Epoch 139/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8438\n",
            "Epoch 140/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8396\n",
            "Epoch 141/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8446\n",
            "Epoch 142/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8508\n",
            "Epoch 143/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8407\n",
            "Epoch 144/150\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 90.8466\n",
            "Epoch 145/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8400\n",
            "Epoch 146/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8484\n",
            "Epoch 147/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8445\n",
            "Epoch 148/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8449\n",
            "Epoch 149/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8465\n",
            "Epoch 150/150\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 90.8555\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 71.1035\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.10352325439453"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQV6zkKXrwR0"
      },
      "source": [
        "#### **Summary of hyperparameter tuning** - **Resumen del ajuste de hiperparámetros**\n",
        "La mayoría de los problemas de aprendizaje automático requieren una gran cantidad de ajustes de hiperparámetros. Desafortunadamente, no podemos proporcionar reglas de ajuste concretas para cada modelo. Reducir la tasa de aprendizaje puede ayudar a que un modelo converja de manera eficiente, pero hacer que otro modelo converja demasiado lentamente. Debe experimentar para encontrar el mejor conjunto de hiperparámetros para su conjunto de datos. Dicho esto, aquí hay algunas reglas generales:\n",
        "\n",
        "* La pérdida de entrenamiento debe disminuir constantemente, abruptamente al principio y luego más lentamente hasta que la pendiente de la curva alcance o se acerque a cero.\n",
        "* Si la pérdida de entrenamiento no converge, entrenar por más épocas.\n",
        "* Si la pérdida de entrenamiento disminuye demasiado lentamente, aumente la tasa de aprendizaje. Tenga en cuenta que establecer una tasa de aprendizaje demasiado alta también puede evitar que la pérdida de entrenamiento converja.\n",
        "* Si la pérdida de entrenamiento varía mucho (es decir, la pérdida de entrenamiento salta), reduzca la tasa de aprendizaje.\n",
        "* Reducir la tasa de aprendizaje mientras se aumenta el número de épocas o el tamaño del lote suele ser una buena combinación.\n",
        "* Establecer el tamaño del lote en un número de lote muy pequeño también puede causar inestabilidad. Primero, pruebe con valores de tamaño de lote grandes. Luego, disminuya el tamaño del lote hasta que vea degradación.\n",
        "* Para conjuntos de datos del mundo real que consisten en una gran cantidad de ejemplos, es posible que el conjunto de datos completo no quepa en la memoria. En tales casos, deberá reducir el tamaño del lote para permitir que un lote quepa en la memoria.\n",
        "\n",
        "Recuerde: la combinación ideal de hiperparámetros depende de los datos, por lo que siempre debe experimentar y verificar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GDb-EBTFuX9"
      },
      "source": [
        "Podemos hacer un procedimiento de ajuste de hiperparámetros de dos maneras:\n",
        "1. Implementación del ajuste de hiperparámetros con Sklearn\n",
        "2. Implementación del ajuste de hiperparámetros con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHo4yEC44ucs"
      },
      "source": [
        "#### **Implementing hyperparameter tuning with Sklearn**\n",
        "Well, we can automate the hyperparameter tunning using **GridSearCV**. GridSearchCV is a hyperparameter search procedure that is done over a defined grid of hyperparameters. Each one of the hyperparameter combinations is used for training a new model, while a cross-validation process is executed to measure the performance of the provisional models. Once the process is done, the hyperparameters and the model with the best performance are chosen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcbe1A171evn"
      },
      "source": [
        "Let's first take a look at the implementation of GridSearchCV with Sklearn, following the steps:\n",
        "1. Define the general architecture of the model\n",
        "2. Define the hyperparameters grid to be validated\n",
        "3. Run the GridSearchCV process\n",
        "4. Print the results of the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofZvGK5eb8Zg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "49593e81-f056-4453-d520-3b39467b41ca"
      },
      "source": [
        "# Import the GridSearchCV class\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Define the model's architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "optimizer = RMSprop(0.1)    # 0.1 is the learning rate\n",
        "model.compile(loss='mean_squared_error',optimizer=optimizer)    # compile the model\n",
        "\n",
        "# 2. Define the hyperparameters grid to be validated\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# 3. Run the GridSearchCV process\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# 4. Print the results of the best model\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f1213a1005ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 3. Run the GridSearchCV process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 4. Print the results of the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;34m\"estimator as it does not implement a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0;34m\"'get_params' method.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7f56a5894b50>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K6RVW_D4JEC"
      },
      "source": [
        "We can observe an error in the hyperparameter tuning procedure using native Sklearn, because the defined model is a Sequential model implemented by Keras, not a scikit-learn estimator. In order to correct this error, we will integrate Sklearn and Keras properly, by (a) creating a `create_model` function that allows to create the model in an automated way, and (b) defining a `KerasRegressor` model which is an implementation of the scikit-learn regressor API for Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBqYpM4bXCCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a1d0c4f4-eefe-42ad-a1dc-d2c1c254815c"
      },
      "source": [
        "# ----------------------------- Functional Tuning - Option 1: using Sklearn  ------------------------------\n",
        "# Goal: tune the batch size and epochs\n",
        "\n",
        "# Import KerasRegressor class\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Define the model trhough a user-defined function\n",
        "def create_model(optimizer=RMSprop(0.01)):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mse', metrics=['mse'], optimizer=optimizer)    # compile the model\n",
        "  return model\n",
        "model = KerasRegressor(build_fn=create_model, verbose=1)\n",
        "\n",
        "# Define the hyperparameters grid to be validated\n",
        "batch_size = [10, 20, 30, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, nb_epoch=epochs)\n",
        "model = KerasRegressor(build_fn=create_model, verbose=1)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Run the GridSearchCV process\n",
        "grid_result = grid.fit(X_train, y_train, verbose = 1)\n",
        "\n",
        "# Print the results of the best model\n",
        "print('Best params: ' + str(grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 0s 1ms/step - loss: 500.3896 - mse: 500.3896\n",
            "Best params: {'batch_size': 10, 'nb_epoch': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5yqTxcWd2tY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "99eb332e-80e5-41a8-a0f5-35b5d5d4351f"
      },
      "source": [
        "# Import the cross validation evaluator\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Measure the model's performance\n",
        "results = cross_val_score(grid.best_estimator_, X_test, y_test, cv=5)\n",
        "print('Results: \\n  * Mean:', -results.mean(), '\\n  * Std:', results.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 335.7493 - mse: 335.7493\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 94.7955 - mse: 94.7955\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 284.1954 - mse: 284.1954\n",
            "WARNING:tensorflow:5 out of the last 39 calls to <function Model.make_test_function.<locals>.test_function at 0x7f83332008c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 65.5752 - mse: 65.5752\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2111.4053 - mse: 2111.4053\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8337e4a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1469.7395 - mse: 1469.7395\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1625.2103 - mse: 1625.2103\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833eb9f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 455.5634 - mse: 455.5634\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1014.8038 - mse: 1014.8038\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f833fa02a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 139.6336 - mse: 139.6336\n",
            "Results: \n",
            "  * Mean: 445.06143951416016 \n",
            "  * Std: 531.0475750207843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwjqAqid476m"
      },
      "source": [
        "#### **Implementing hyperparameter tuning with Keras**\n",
        "Now we will go through the process of automating hyperparameter tuning using **Random Search** and **Keras**. Random Search is a hyperparameter search procedure that is performed on a defined grid of hyperparameters. However, not all hyperparameter combinations are used to train a new model, only some selected randomly, while a process of cross-validation to measure the performance of temporal models. Once the process is complete, the hyperparameters and the best performing model are chosen.\n",
        "\n",
        "Let's take a look at the implementation of Random Search with Keras, following the steps:\n",
        "\n",
        "0. Install and import all the packages needed\n",
        "1. Define the general architecture of the model through a creation function\n",
        "2. Define the hyperparameters grid to be validated\n",
        "3. Run the GridSearchCV process\n",
        "4. Print the results of the best model\n",
        "\n",
        "To execute the hyperparameter tuning procedure we will use the `keras-tuner`, a library that helps you pick the optimal set of hyperparameters for your TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inRKd7kY2NEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79bfbd63-9295-473d-d45d-b099a1e737a6"
      },
      "source": [
        "# ----------------------------- Functional Tuning - Option 2: using Keras Tuner ------------------------------\n",
        "# Goal: tune the learning rate\n",
        "\n",
        "# 0. Install and import all the packages needed\n",
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt\n",
        "\n",
        "# 1. Define the general architecture of the model through a creation user-defined function\n",
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-1, 1e-2, 1e-3, 1e-4]) # Tuning the learning rate (four different values to test: 0.1, 0.01, 0.001, 0.0001)\n",
        "  optimizer = RMSprop(learning_rate = hp_learning_rate)                            # Defining the optimizer\n",
        "  model.compile(loss='mse',metrics=['mse'], optimizer=optimizer)                   # Compiling the model \n",
        "  return model                                                                     # Returning the defined model\n",
        "\n",
        "# 2. Define the hyperparameters grid to be validated\n",
        "tuner_rs = kt.RandomSearch(\n",
        "              model_builder,                # Takes hyperparameters (hp) and returns a Model instance\n",
        "              objective = 'mse',            # Name of model metric to minimize or maximize\n",
        "              seed = 42,                    # Random seed for replication purposes\n",
        "              max_trials = 5,               # Total number of trials (model configurations) to test at most. Note that the oracle may interrupt the search before max_trial models have been tested.\n",
        "              directory='random_search')    # Path to the working directory (relative).\n",
        "\n",
        "# 3. Run the GridSearchCV process\n",
        "tuner_rs.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 5115.7114 - mse: 5115.7114 - val_loss: 527.6143 - val_mse: 527.6143\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 631.4748 - mse: 631.4748 - val_loss: 486.6498 - val_mse: 486.6498\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 591.8683 - mse: 591.8683 - val_loss: 451.8018 - val_mse: 451.8018\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 553.3091 - mse: 553.3091 - val_loss: 405.2310 - val_mse: 405.2310\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 415.7266 - mse: 415.7266 - val_loss: 137.3820 - val_mse: 137.3820\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 181.2757 - mse: 181.2757 - val_loss: 349.1423 - val_mse: 349.1423\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 241.5480 - mse: 241.5480 - val_loss: 628.4697 - val_mse: 628.4697\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 427.2863 - mse: 427.2863 - val_loss: 153.9367 - val_mse: 153.9367\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 121.7307 - mse: 121.7307 - val_loss: 87.7117 - val_mse: 87.7117\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 143.4021 - mse: 143.4021 - val_loss: 3868.4473 - val_mse: 3868.4473\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7119.2725 - mse: 7119.2725 - val_loss: 49.7455 - val_mse: 49.7455\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 94.0848 - mse: 94.0848 - val_loss: 119.7478 - val_mse: 119.7478\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 106.9504 - mse: 106.9504 - val_loss: 200.1315 - val_mse: 200.1315\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 133.2470 - mse: 133.2470 - val_loss: 1621.7432 - val_mse: 1621.7432\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 542.2847 - mse: 542.2847 - val_loss: 259.2349 - val_mse: 259.2349\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 167.7371 - mse: 167.7371 - val_loss: 133.8815 - val_mse: 133.8815\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 219.6196 - mse: 219.6196 - val_loss: 6029.8018 - val_mse: 6029.8018\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1249.7904 - mse: 1249.7904 - val_loss: 331.4357 - val_mse: 331.4357\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 394.7971 - mse: 394.7971 - val_loss: 235.2882 - val_mse: 235.2882\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 273.5750 - mse: 273.5750 - val_loss: 115.4428 - val_mse: 115.4428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: a22ee1034e8ea2401e4b61fb1a0173b2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 107.90773391723633</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 2369.5652 - mse: 2369.5652 - val_loss: 2086.2415 - val_mse: 2086.2415\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2319.8223 - mse: 2319.8223 - val_loss: 2047.9214 - val_mse: 2047.9214\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2281.5579 - mse: 2281.5579 - val_loss: 2013.5859 - val_mse: 2013.5859\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2246.2014 - mse: 2246.2014 - val_loss: 1980.2305 - val_mse: 1980.2305\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2211.8816 - mse: 2211.8816 - val_loss: 1951.4897 - val_mse: 1951.4897\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2181.1345 - mse: 2181.1345 - val_loss: 1919.9293 - val_mse: 1919.9293\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2148.5950 - mse: 2148.5950 - val_loss: 1888.0750 - val_mse: 1888.0750\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2116.1487 - mse: 2116.1487 - val_loss: 1857.7325 - val_mse: 1857.7325\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2084.9092 - mse: 2084.9092 - val_loss: 1827.8527 - val_mse: 1827.8527\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2054.2222 - mse: 2054.2222 - val_loss: 1798.5969 - val_mse: 1798.5969\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 46262.2500 - mse: 46262.2500 - val_loss: 52689.9102 - val_mse: 52689.9102\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 44406.0391 - mse: 44406.0391 - val_loss: 51135.9492 - val_mse: 51135.9492\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 43084.2109 - mse: 43084.2109 - val_loss: 49638.4531 - val_mse: 49638.4531\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 41827.6094 - mse: 41827.6094 - val_loss: 48166.7031 - val_mse: 48166.7031\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 40603.2734 - mse: 40603.2734 - val_loss: 46720.9102 - val_mse: 46720.9102\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 39382.1953 - mse: 39382.1953 - val_loss: 45200.4766 - val_mse: 45200.4766\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 38124.4648 - mse: 38124.4648 - val_loss: 43779.2305 - val_mse: 43779.2305\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 36953.8125 - mse: 36953.8125 - val_loss: 42453.3242 - val_mse: 42453.3242\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 35829.7500 - mse: 35829.7500 - val_loss: 41130.1445 - val_mse: 41130.1445\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 34717.1055 - mse: 34717.1055 - val_loss: 39952.5430 - val_mse: 39952.5430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: cafa3fde4808ac9b513957c21fb1bb15</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 18385.663818359375</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 167.4187 - mse: 167.4187 - val_loss: 111.0479 - val_mse: 111.0479\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 152.3961 - mse: 152.3961 - val_loss: 99.7410 - val_mse: 99.7410\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 144.1482 - mse: 144.1482 - val_loss: 91.9177 - val_mse: 91.9177\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 137.6506 - mse: 137.6506 - val_loss: 85.9139 - val_mse: 85.9139\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 133.1032 - mse: 133.1032 - val_loss: 81.7799 - val_mse: 81.7799\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 128.7415 - mse: 128.7415 - val_loss: 78.0218 - val_mse: 78.0218\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 124.9512 - mse: 124.9512 - val_loss: 74.4188 - val_mse: 74.4188\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 121.6608 - mse: 121.6608 - val_loss: 71.6401 - val_mse: 71.6401\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 118.4186 - mse: 118.4186 - val_loss: 68.5571 - val_mse: 68.5571\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 114.7115 - mse: 114.7115 - val_loss: 66.8739 - val_mse: 66.8739\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 36598.7344 - mse: 36598.7344 - val_loss: 22937.0820 - val_mse: 22937.0820\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 19166.4160 - mse: 19166.4160 - val_loss: 12131.9092 - val_mse: 12131.9092\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10303.7236 - mse: 10303.7236 - val_loss: 5962.5356 - val_mse: 5962.5356\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5258.7271 - mse: 5258.7271 - val_loss: 3021.6514 - val_mse: 3021.6514\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2794.2710 - mse: 2794.2710 - val_loss: 2153.0938 - val_mse: 2153.0938\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 1964.4718 - mse: 1964.4718 - val_loss: 1860.6332 - val_mse: 1860.6332\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1626.5642 - mse: 1626.5642 - val_loss: 1628.3406 - val_mse: 1628.3406\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1364.4591 - mse: 1364.4591 - val_loss: 1365.9147 - val_mse: 1365.9147\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1132.6879 - mse: 1132.6879 - val_loss: 1114.1368 - val_mse: 1114.1368\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 934.8654 - mse: 934.8654 - val_loss: 1227.3302 - val_mse: 1227.3302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 0ceae8bd9ae08bcb7b22c37b7bff1f56</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 524.7884521484375</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 344.1214 - mse: 344.1214 - val_loss: 285.5694 - val_mse: 285.5694\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 159.7777 - mse: 159.7777 - val_loss: 238.0298 - val_mse: 238.0298\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 165.3195 - mse: 165.3195 - val_loss: 193.2417 - val_mse: 193.2417\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 141.4814 - mse: 141.4814 - val_loss: 584.3061 - val_mse: 584.3061\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 141.6709 - mse: 141.6709 - val_loss: 136.0439 - val_mse: 136.0439\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 135.3921 - mse: 135.3921 - val_loss: 522.0715 - val_mse: 522.0715\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 150.2538 - mse: 150.2538 - val_loss: 673.9136 - val_mse: 673.9136\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 190.2688 - mse: 190.2688 - val_loss: 150.2733 - val_mse: 150.2733\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 95.3549 - mse: 95.3549 - val_loss: 45.8120 - val_mse: 45.8120\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 112.0679 - mse: 112.0679 - val_loss: 621.9553 - val_mse: 621.9553\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 686.0698 - mse: 686.0698 - val_loss: 226.5338 - val_mse: 226.5338\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 135.9570 - mse: 135.9570 - val_loss: 60.8812 - val_mse: 60.8812\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 79.1926 - mse: 79.1926 - val_loss: 72.5660 - val_mse: 72.5660\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 99.2560 - mse: 99.2560 - val_loss: 435.5785 - val_mse: 435.5785\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 107.4537 - mse: 107.4537 - val_loss: 59.1401 - val_mse: 59.1401\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 101.4841 - mse: 101.4841 - val_loss: 237.7310 - val_mse: 237.7310\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 114.9605 - mse: 114.9605 - val_loss: 618.4346 - val_mse: 618.4346\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 156.3545 - mse: 156.3545 - val_loss: 52.5405 - val_mse: 52.5405\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 73.1649 - mse: 73.1649 - val_loss: 35.8674 - val_mse: 35.8674\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 80.7216 - mse: 80.7216 - val_loss: 505.6774 - val_mse: 505.6774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e92a94e0c97a452405ab725f169fff93</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 84.25988388061523</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRy9Aaby_dQt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "2af1db5e-1e08-4a73-9381-a5827d057dca"
      },
      "source": [
        "# 4.1. Print the summary results of the hyperparameter tuning procedure\n",
        "tuner_rs.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in random_search/untitled_project</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective(name='mse', direction='min')</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e92a94e0c97a452405ab725f169fff93</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 84.25988388061523</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: a22ee1034e8ea2401e4b61fb1a0173b2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 107.90773391723633</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 0ceae8bd9ae08bcb7b22c37b7bff1f56</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 524.7884521484375</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: cafa3fde4808ac9b513957c21fb1bb15</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 18385.663818359375</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq_625b19g6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72326de4-7d9c-4648-b45c-27ac8224154c"
      },
      "source": [
        "# 4.2. Print the results of the best model\n",
        "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
        "best_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 48.6127 - mse: 48.6127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[48.612728118896484, 48.612728118896484]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxM4hL6r9Vz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "029bf07d-26ce-4db9-a409-cdcb04052e45"
      },
      "source": [
        "# 4.3. Print the best model's architecture\n",
        "best_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 237\n",
            "Trainable params: 237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYL0qp4fTv-"
      },
      "source": [
        "#### 5. Make a Prediction\n",
        "Making a prediction is the final step in the life-cycle. It is why we wanted the model in the first place.\n",
        "\n",
        "It requires you have new data for which a prediction is required, e.g. where you do not have the target values.\n",
        "\n",
        "From an API perspective, you simply call a function to make a prediction of a class label, probability, or numerical value: whatever you designed your model to predict.\n",
        "\n",
        "We have our new test data located at the given github location:\n",
        "\n",
        "https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-fWHtrMe8U_"
      },
      "source": [
        "# Load new test data\n",
        "new_test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crRYu0YtiO5G"
      },
      "source": [
        "# make a prediction\n",
        "model.predict(new_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuoFhNRrn623"
      },
      "source": [
        "\n",
        "**Congratulations! You have successfully build your first deep learning model and predicted the output (i.e. MEDV) of new test data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-SLnxZxp02g"
      },
      "source": [
        "#### Resources\n",
        "*  [https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/)\n",
        "*  [https://heartbeat.fritz.ai/linear-regression-using-keras-and-python-7cee2819a60c](https://heartbeat.fritz.ai/linear-regression-using-keras-and-python-7cee2819a60c)\n",
        "*  Google Machine Learning Crash Course"
      ]
    }
  ]
}